[2023-09-30 11:30:02,318][00932] Saving configuration to logs/sf/Soccer_0/config.json...
[2023-09-30 11:30:02,320][00932] Rollout worker 0 uses device cpu
[2023-09-30 11:30:02,320][00932] Rollout worker 1 uses device cpu
[2023-09-30 11:30:02,320][00932] Rollout worker 2 uses device cpu
[2023-09-30 11:30:02,320][00932] Rollout worker 3 uses device cpu
[2023-09-30 11:30:02,321][00932] Rollout worker 4 uses device cpu
[2023-09-30 11:30:02,321][00932] Rollout worker 5 uses device cpu
[2023-09-30 11:30:02,321][00932] Rollout worker 6 uses device cpu
[2023-09-30 11:30:02,321][00932] Rollout worker 7 uses device cpu
[2023-09-30 11:30:02,321][00932] Rollout worker 8 uses device cpu
[2023-09-30 11:30:02,321][00932] Rollout worker 9 uses device cpu
[2023-09-30 11:30:02,332][00932] Saving policy-specific configuration 0 to file logs/sf/Soccer_0/policy_00_cfg.json
[2023-09-30 11:30:02,333][00932] Saving policy-specific reward shaping 0 to file logs/sf/Soccer_0/policy_00_reward_shaping.json
[2023-09-30 11:30:02,341][00932] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2023-09-30 11:30:02,341][00932] InferenceWorker_p0-w0: min num requests: 3
[2023-09-30 11:30:02,364][00932] Starting all processes...
[2023-09-30 11:30:02,364][00932] Starting process learner_proc0
[2023-09-30 11:30:02,366][00932] Starting all processes...
[2023-09-30 11:30:02,369][00932] Starting process inference_proc0-0
[2023-09-30 11:30:02,369][00932] Starting process rollout_proc0
[2023-09-30 11:30:02,369][00932] Starting process rollout_proc1
[2023-09-30 11:30:02,369][00932] Starting process rollout_proc2
[2023-09-30 11:30:02,369][00932] Starting process rollout_proc3
[2023-09-30 11:30:02,369][00932] Starting process rollout_proc4
[2023-09-30 11:30:02,369][00932] Starting process rollout_proc5
[2023-09-30 11:30:02,370][00932] Starting process rollout_proc6
[2023-09-30 11:30:02,370][00932] Starting process rollout_proc7
[2023-09-30 11:30:02,370][00932] Starting process rollout_proc8
[2023-09-30 11:30:02,370][00932] Starting process rollout_proc9
[2023-09-30 11:30:02,429][00932] Sending learning configuration to learner 0...
[2023-09-30 11:30:07,173][00988] Worker 3 uses CPU cores [3]
[2023-09-30 11:30:07,237][00989] Worker 8 uses CPU cores [0, 1]
[2023-09-30 11:30:07,537][00994] Worker 6 uses CPU cores [2]
[2023-09-30 11:30:07,547][00999] Worker 7 uses CPU cores [3]
[2023-09-30 11:30:07,597][00990] Worker 2 uses CPU cores [2]
[2023-09-30 11:30:07,629][00995] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2023-09-30 11:30:07,629][00995] Set environment var CUDA_VISIBLE_DEVICES to '0' (GPU indices [0]) for inference process 0
[2023-09-30 11:30:07,648][00996] Worker 9 uses CPU cores [2, 3]
[2023-09-30 11:30:07,654][00972] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2023-09-30 11:30:07,654][00972] Set environment var CUDA_VISIBLE_DEVICES to '0' (GPU indices [0]) for learning process 0
[2023-09-30 11:30:07,676][00998] Worker 1 uses CPU cores [1]
[2023-09-30 11:30:07,680][00997] Worker 0 uses CPU cores [0]
[2023-09-30 11:30:07,716][01000] Worker 4 uses CPU cores [0]
[2023-09-30 11:30:07,745][00987] Worker 5 uses CPU cores [1]
[2023-09-30 11:30:07,746][00995] Num visible devices: 1
[2023-09-30 11:30:07,746][00972] Num visible devices: 1
[2023-09-30 11:30:07,778][00972] Starting seed is not provided
[2023-09-30 11:30:07,778][00972] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2023-09-30 11:30:07,778][00972] Initializing actor-critic model on device cuda:0
[2023-09-30 11:30:07,779][00972] RunningMeanStd input shape: (129,)
[2023-09-30 11:30:07,779][00972] RunningMeanStd input shape: (1,)
[2023-09-30 11:30:07,878][00972] Created Actor Critic model with architecture:
[2023-09-30 11:30:07,878][00972] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (obs): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ReLU)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=ReLU)
        )
      )
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(512, 512)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=512, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=512, out_features=10, bias=True)
  )
)
[2023-09-30 11:30:08,776][00972] Using optimizer <class 'torch.optim.adam.Adam'>
[2023-09-30 11:30:08,776][00972] No checkpoints found
[2023-09-30 11:30:08,776][00972] Did not load from checkpoint, starting from scratch!
[2023-09-30 11:30:08,777][00972] Initialized policy 0 weights for model version 0
[2023-09-30 11:30:08,778][00972] LearnerWorker_p0 finished initialization!
[2023-09-30 11:30:08,779][00972] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2023-09-30 11:30:09,237][00995] RunningMeanStd input shape: (129,)
[2023-09-30 11:30:09,237][00995] RunningMeanStd input shape: (1,)
[2023-09-30 11:30:09,718][00932] Inference worker 0-0 is ready!
[2023-09-30 11:30:09,718][00932] All inference workers are ready! Signal rollout workers to start!
[2023-09-30 11:30:11,067][00988] Decorrelating experience for 0 frames...
[2023-09-30 11:30:11,070][00999] Decorrelating experience for 0 frames...
[2023-09-30 11:30:11,091][00997] Decorrelating experience for 0 frames...
[2023-09-30 11:30:11,099][00996] Decorrelating experience for 0 frames...
[2023-09-30 11:30:11,101][00998] Decorrelating experience for 0 frames...
[2023-09-30 11:30:11,104][00987] Decorrelating experience for 0 frames...
[2023-09-30 11:30:11,117][00989] Decorrelating experience for 0 frames...
[2023-09-30 11:30:11,119][01000] Decorrelating experience for 0 frames...
[2023-09-30 11:30:11,143][00994] Decorrelating experience for 0 frames...
[2023-09-30 11:30:11,145][00990] Decorrelating experience for 0 frames...
[2023-09-30 11:30:12,271][00932] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2023-09-30 11:30:12,424][00988] Decorrelating experience for 32 frames...
[2023-09-30 11:30:12,429][00999] Decorrelating experience for 32 frames...
[2023-09-30 11:30:12,433][00996] Decorrelating experience for 32 frames...
[2023-09-30 11:30:12,478][00997] Decorrelating experience for 32 frames...
[2023-09-30 11:30:12,484][00987] Decorrelating experience for 32 frames...
[2023-09-30 11:30:12,486][01000] Decorrelating experience for 32 frames...
[2023-09-30 11:30:12,489][00998] Decorrelating experience for 32 frames...
[2023-09-30 11:30:12,500][00989] Decorrelating experience for 32 frames...
[2023-09-30 11:30:12,525][00994] Decorrelating experience for 32 frames...
[2023-09-30 11:30:12,532][00990] Decorrelating experience for 32 frames...
[2023-09-30 11:30:14,657][00972] Optimizer lr value 0.0000300, betas: (0.9, 0.999)
[2023-09-30 11:30:16,094][00995] Updated weights for policy 0, policy_version 10 (0.0010)
[2023-09-30 11:30:17,271][00932] Fps is (10 sec: 819.2, 60 sec: 819.2, 300 sec: 819.2). Total num frames: 4096. Throughput: 0: 1444.0. Samples: 7220. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[2023-09-30 11:30:17,499][00995] Updated weights for policy 0, policy_version 23 (0.0009)
[2023-09-30 11:30:17,626][00995] Updated weights for policy 0, policy_version 34 (0.0005)
[2023-09-30 11:30:18,748][00995] Updated weights for policy 0, policy_version 44 (0.0011)
[2023-09-30 11:30:18,860][00995] Updated weights for policy 0, policy_version 54 (0.0008)
[2023-09-30 11:30:19,892][00995] Updated weights for policy 0, policy_version 64 (0.0005)
[2023-09-30 11:30:20,039][00995] Updated weights for policy 0, policy_version 74 (0.0005)
[2023-09-30 11:30:21,561][00995] Updated weights for policy 0, policy_version 84 (0.0012)
[2023-09-30 11:30:21,679][00995] Updated weights for policy 0, policy_version 94 (0.0008)
[2023-09-30 11:30:22,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2048.0, 300 sec: 2048.0). Total num frames: 20480. Throughput: 0: 2152.6. Samples: 21526. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:30:22,336][00932] Heartbeat connected on Batcher_0
[2023-09-30 11:30:22,338][00932] Heartbeat connected on LearnerWorker_p0
[2023-09-30 11:30:22,347][00932] Heartbeat connected on InferenceWorker_p0-w0
[2023-09-30 11:30:22,351][00932] Heartbeat connected on RolloutWorker_w2
[2023-09-30 11:30:22,354][00932] Heartbeat connected on RolloutWorker_w1
[2023-09-30 11:30:22,354][00932] Heartbeat connected on RolloutWorker_w4
[2023-09-30 11:30:22,357][00932] Heartbeat connected on RolloutWorker_w0
[2023-09-30 11:30:22,357][00932] Heartbeat connected on RolloutWorker_w3
[2023-09-30 11:30:22,361][00932] Heartbeat connected on RolloutWorker_w5
[2023-09-30 11:30:22,365][00932] Heartbeat connected on RolloutWorker_w8
[2023-09-30 11:30:22,372][00932] Heartbeat connected on RolloutWorker_w6
[2023-09-30 11:30:22,376][00932] Heartbeat connected on RolloutWorker_w7
[2023-09-30 11:30:22,378][00932] Heartbeat connected on RolloutWorker_w9
[2023-09-30 11:30:23,198][00995] Updated weights for policy 0, policy_version 105 (0.0009)
[2023-09-30 11:30:23,336][00995] Updated weights for policy 0, policy_version 116 (0.0008)
[2023-09-30 11:30:24,813][00995] Updated weights for policy 0, policy_version 127 (0.0005)
[2023-09-30 11:30:24,932][00995] Updated weights for policy 0, policy_version 137 (0.0011)
[2023-09-30 11:30:26,503][00995] Updated weights for policy 0, policy_version 149 (0.0006)
[2023-09-30 11:30:26,612][00995] Updated weights for policy 0, policy_version 159 (0.0015)
[2023-09-30 11:30:27,271][00932] Fps is (10 sec: 2867.2, 60 sec: 2184.5, 300 sec: 2184.5). Total num frames: 32768. Throughput: 0: 1939.3. Samples: 29090. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:30:27,280][00932] Avg episode reward: [(0, '1.731')]
[2023-09-30 11:30:28,015][00995] Updated weights for policy 0, policy_version 169 (0.0007)
[2023-09-30 11:30:28,171][00995] Updated weights for policy 0, policy_version 179 (0.0005)
[2023-09-30 11:30:29,599][00995] Updated weights for policy 0, policy_version 189 (0.0015)
[2023-09-30 11:30:29,732][00995] Updated weights for policy 0, policy_version 199 (0.0012)
[2023-09-30 11:30:31,247][00995] Updated weights for policy 0, policy_version 209 (0.0005)
[2023-09-30 11:30:31,375][00995] Updated weights for policy 0, policy_version 219 (0.0005)
[2023-09-30 11:30:32,271][00932] Fps is (10 sec: 2457.6, 60 sec: 2252.8, 300 sec: 2252.8). Total num frames: 45056. Throughput: 0: 2226.0. Samples: 44520. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:30:32,272][00932] Avg episode reward: [(0, '1.775')]
[2023-09-30 11:30:32,925][00995] Updated weights for policy 0, policy_version 229 (0.0011)
[2023-09-30 11:30:33,043][00995] Updated weights for policy 0, policy_version 239 (0.0006)
[2023-09-30 11:30:34,536][00995] Updated weights for policy 0, policy_version 249 (0.0014)
[2023-09-30 11:30:34,661][00995] Updated weights for policy 0, policy_version 260 (0.0011)
[2023-09-30 11:30:36,148][00995] Updated weights for policy 0, policy_version 272 (0.0005)
[2023-09-30 11:30:37,271][00932] Fps is (10 sec: 2457.6, 60 sec: 2293.8, 300 sec: 2293.8). Total num frames: 57344. Throughput: 0: 2379.3. Samples: 59482. Policy #0 lag: (min: 16.0, avg: 24.1, max: 36.0)
[2023-09-30 11:30:37,272][00932] Avg episode reward: [(0, '1.775')]
[2023-09-30 11:30:37,692][00995] Updated weights for policy 0, policy_version 282 (0.0018)
[2023-09-30 11:30:37,834][00995] Updated weights for policy 0, policy_version 292 (0.0013)
[2023-09-30 11:30:39,327][00995] Updated weights for policy 0, policy_version 302 (0.0011)
[2023-09-30 11:30:39,471][00995] Updated weights for policy 0, policy_version 312 (0.0014)
[2023-09-30 11:30:40,897][00995] Updated weights for policy 0, policy_version 322 (0.0005)
[2023-09-30 11:30:41,034][00995] Updated weights for policy 0, policy_version 332 (0.0007)
[2023-09-30 11:30:42,272][00932] Fps is (10 sec: 2457.5, 60 sec: 2321.0, 300 sec: 2321.0). Total num frames: 69632. Throughput: 0: 2235.8. Samples: 67074. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2023-09-30 11:30:42,272][00932] Avg episode reward: [(0, '1.783')]
[2023-09-30 11:30:42,664][00995] Updated weights for policy 0, policy_version 342 (0.0005)
[2023-09-30 11:30:42,807][00995] Updated weights for policy 0, policy_version 352 (0.0005)
[2023-09-30 11:30:44,297][00995] Updated weights for policy 0, policy_version 362 (0.0005)
[2023-09-30 11:30:44,427][00995] Updated weights for policy 0, policy_version 372 (0.0005)
[2023-09-30 11:30:45,975][00995] Updated weights for policy 0, policy_version 383 (0.0005)
[2023-09-30 11:30:46,120][00995] Updated weights for policy 0, policy_version 393 (0.0005)
[2023-09-30 11:30:47,271][00932] Fps is (10 sec: 2457.6, 60 sec: 2340.6, 300 sec: 2340.6). Total num frames: 81920. Throughput: 0: 2344.3. Samples: 82050. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:30:47,272][00932] Avg episode reward: [(0, '1.730')]
[2023-09-30 11:30:47,693][00995] Updated weights for policy 0, policy_version 404 (0.0005)
[2023-09-30 11:30:47,816][00995] Updated weights for policy 0, policy_version 414 (0.0009)
[2023-09-30 11:30:49,531][00995] Updated weights for policy 0, policy_version 424 (0.0005)
[2023-09-30 11:30:49,658][00995] Updated weights for policy 0, policy_version 434 (0.0010)
[2023-09-30 11:30:51,343][00995] Updated weights for policy 0, policy_version 445 (0.0005)
[2023-09-30 11:30:51,460][00995] Updated weights for policy 0, policy_version 456 (0.0010)
[2023-09-30 11:30:52,271][00932] Fps is (10 sec: 2457.7, 60 sec: 2355.2, 300 sec: 2355.2). Total num frames: 94208. Throughput: 0: 2392.6. Samples: 95706. Policy #0 lag: (min: 6.0, avg: 11.8, max: 26.0)
[2023-09-30 11:30:52,280][00932] Avg episode reward: [(0, '1.730')]
[2023-09-30 11:30:53,224][00995] Updated weights for policy 0, policy_version 467 (0.0012)
[2023-09-30 11:30:53,347][00995] Updated weights for policy 0, policy_version 478 (0.0013)
[2023-09-30 11:30:55,147][00995] Updated weights for policy 0, policy_version 490 (0.0006)
[2023-09-30 11:30:55,263][00995] Updated weights for policy 0, policy_version 500 (0.0005)
[2023-09-30 11:30:57,091][00995] Updated weights for policy 0, policy_version 511 (0.0009)
[2023-09-30 11:30:57,271][00932] Fps is (10 sec: 2457.6, 60 sec: 2366.6, 300 sec: 2366.6). Total num frames: 106496. Throughput: 0: 2277.4. Samples: 102482. Policy #0 lag: (min: 6.0, avg: 14.5, max: 26.0)
[2023-09-30 11:30:57,272][00932] Avg episode reward: [(0, '1.743')]
[2023-09-30 11:30:57,282][00972] Saving new best policy, reward=1.743!
[2023-09-30 11:30:58,779][00995] Updated weights for policy 0, policy_version 522 (0.0010)
[2023-09-30 11:30:58,895][00995] Updated weights for policy 0, policy_version 532 (0.0006)
[2023-09-30 11:31:00,457][00995] Updated weights for policy 0, policy_version 542 (0.0014)
[2023-09-30 11:31:00,595][00995] Updated weights for policy 0, policy_version 552 (0.0005)
[2023-09-30 11:31:02,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2293.8, 300 sec: 2293.8). Total num frames: 114688. Throughput: 0: 2410.8. Samples: 115706. Policy #0 lag: (min: 4.0, avg: 13.7, max: 24.0)
[2023-09-30 11:31:02,280][00932] Avg episode reward: [(0, '1.725')]
[2023-09-30 11:31:02,301][00995] Updated weights for policy 0, policy_version 563 (0.0005)
[2023-09-30 11:31:02,433][00995] Updated weights for policy 0, policy_version 573 (0.0005)
[2023-09-30 11:31:04,247][00995] Updated weights for policy 0, policy_version 583 (0.0020)
[2023-09-30 11:31:04,381][00995] Updated weights for policy 0, policy_version 593 (0.0008)
[2023-09-30 11:31:06,159][00995] Updated weights for policy 0, policy_version 603 (0.0005)
[2023-09-30 11:31:06,279][00995] Updated weights for policy 0, policy_version 613 (0.0005)
[2023-09-30 11:31:07,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2308.7, 300 sec: 2308.7). Total num frames: 126976. Throughput: 0: 2384.1. Samples: 128810. Policy #0 lag: (min: 17.0, avg: 17.0, max: 17.0)
[2023-09-30 11:31:07,280][00932] Avg episode reward: [(0, '1.710')]
[2023-09-30 11:31:08,005][00995] Updated weights for policy 0, policy_version 623 (0.0006)
[2023-09-30 11:31:08,117][00995] Updated weights for policy 0, policy_version 633 (0.0008)
[2023-09-30 11:31:09,884][00995] Updated weights for policy 0, policy_version 643 (0.0012)
[2023-09-30 11:31:10,024][00995] Updated weights for policy 0, policy_version 653 (0.0010)
[2023-09-30 11:31:11,669][00995] Updated weights for policy 0, policy_version 664 (0.0006)
[2023-09-30 11:31:11,783][00995] Updated weights for policy 0, policy_version 674 (0.0010)
[2023-09-30 11:31:12,271][00932] Fps is (10 sec: 2457.6, 60 sec: 2321.1, 300 sec: 2321.1). Total num frames: 139264. Throughput: 0: 2366.0. Samples: 135560. Policy #0 lag: (min: 14.0, avg: 21.6, max: 34.0)
[2023-09-30 11:31:12,272][00932] Avg episode reward: [(0, '1.710')]
[2023-09-30 11:31:13,449][00995] Updated weights for policy 0, policy_version 685 (0.0008)
[2023-09-30 11:31:13,586][00995] Updated weights for policy 0, policy_version 695 (0.0008)
[2023-09-30 11:31:15,374][00995] Updated weights for policy 0, policy_version 705 (0.0005)
[2023-09-30 11:31:15,498][00995] Updated weights for policy 0, policy_version 715 (0.0005)
[2023-09-30 11:31:17,111][00995] Updated weights for policy 0, policy_version 725 (0.0005)
[2023-09-30 11:31:17,233][00995] Updated weights for policy 0, policy_version 735 (0.0005)
[2023-09-30 11:31:17,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2389.3, 300 sec: 2268.6). Total num frames: 147456. Throughput: 0: 2319.0. Samples: 148876. Policy #0 lag: (min: 16.0, avg: 22.8, max: 36.0)
[2023-09-30 11:31:17,281][00932] Avg episode reward: [(0, '1.686')]
[2023-09-30 11:31:18,917][00995] Updated weights for policy 0, policy_version 745 (0.0013)
[2023-09-30 11:31:19,055][00995] Updated weights for policy 0, policy_version 757 (0.0005)
[2023-09-30 11:31:20,748][00995] Updated weights for policy 0, policy_version 767 (0.0010)
[2023-09-30 11:31:20,870][00995] Updated weights for policy 0, policy_version 777 (0.0017)
[2023-09-30 11:31:22,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2321.1, 300 sec: 2282.1). Total num frames: 159744. Throughput: 0: 2292.1. Samples: 162626. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:31:22,272][00932] Avg episode reward: [(0, '1.676')]
[2023-09-30 11:31:22,610][00995] Updated weights for policy 0, policy_version 787 (0.0005)
[2023-09-30 11:31:22,721][00995] Updated weights for policy 0, policy_version 797 (0.0008)
[2023-09-30 11:31:24,645][00995] Updated weights for policy 0, policy_version 807 (0.0005)
[2023-09-30 11:31:24,771][00995] Updated weights for policy 0, policy_version 817 (0.0010)
[2023-09-30 11:31:26,649][00995] Updated weights for policy 0, policy_version 827 (0.0005)
[2023-09-30 11:31:26,786][00995] Updated weights for policy 0, policy_version 837 (0.0005)
[2023-09-30 11:31:27,271][00932] Fps is (10 sec: 2457.6, 60 sec: 2321.1, 300 sec: 2293.8). Total num frames: 172032. Throughput: 0: 2262.9. Samples: 168906. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:31:27,272][00932] Avg episode reward: [(0, '1.643')]
[2023-09-30 11:31:28,506][00995] Updated weights for policy 0, policy_version 847 (0.0009)
[2023-09-30 11:31:28,623][00995] Updated weights for policy 0, policy_version 857 (0.0006)
[2023-09-30 11:31:30,344][00995] Updated weights for policy 0, policy_version 867 (0.0006)
[2023-09-30 11:31:30,482][00995] Updated weights for policy 0, policy_version 877 (0.0015)
[2023-09-30 11:31:32,265][00995] Updated weights for policy 0, policy_version 887 (0.0008)
[2023-09-30 11:31:32,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2252.8, 300 sec: 2252.8). Total num frames: 180224. Throughput: 0: 2216.4. Samples: 181786. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:31:32,280][00932] Avg episode reward: [(0, '1.644')]
[2023-09-30 11:31:32,407][00995] Updated weights for policy 0, policy_version 897 (0.0005)
[2023-09-30 11:31:34,108][00995] Updated weights for policy 0, policy_version 907 (0.0011)
[2023-09-30 11:31:34,246][00995] Updated weights for policy 0, policy_version 917 (0.0010)
[2023-09-30 11:31:35,944][00995] Updated weights for policy 0, policy_version 927 (0.0005)
[2023-09-30 11:31:36,064][00995] Updated weights for policy 0, policy_version 937 (0.0009)
[2023-09-30 11:31:37,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2252.8, 300 sec: 2264.8). Total num frames: 192512. Throughput: 0: 2206.0. Samples: 194974. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-09-30 11:31:37,272][00932] Avg episode reward: [(0, '1.659')]
[2023-09-30 11:31:37,791][00995] Updated weights for policy 0, policy_version 947 (0.0010)
[2023-09-30 11:31:37,940][00995] Updated weights for policy 0, policy_version 957 (0.0005)
[2023-09-30 11:31:39,684][00995] Updated weights for policy 0, policy_version 968 (0.0007)
[2023-09-30 11:31:39,821][00995] Updated weights for policy 0, policy_version 979 (0.0005)
[2023-09-30 11:31:41,590][00995] Updated weights for policy 0, policy_version 989 (0.0011)
[2023-09-30 11:31:41,710][00995] Updated weights for policy 0, policy_version 1000 (0.0010)
[2023-09-30 11:31:42,271][00932] Fps is (10 sec: 2457.6, 60 sec: 2252.8, 300 sec: 2275.6). Total num frames: 204800. Throughput: 0: 2202.3. Samples: 201584. Policy #0 lag: (min: 19.0, avg: 20.9, max: 39.0)
[2023-09-30 11:31:42,272][00932] Avg episode reward: [(0, '1.659')]
[2023-09-30 11:31:43,434][00995] Updated weights for policy 0, policy_version 1010 (0.0005)
[2023-09-30 11:31:43,568][00995] Updated weights for policy 0, policy_version 1020 (0.0005)
[2023-09-30 11:31:45,249][00995] Updated weights for policy 0, policy_version 1031 (0.0010)
[2023-09-30 11:31:47,038][00995] Updated weights for policy 0, policy_version 1042 (0.0012)
[2023-09-30 11:31:47,178][00995] Updated weights for policy 0, policy_version 1052 (0.0005)
[2023-09-30 11:31:47,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2184.5, 300 sec: 2242.0). Total num frames: 212992. Throughput: 0: 2201.2. Samples: 214762. Policy #0 lag: (min: 18.0, avg: 26.9, max: 38.0)
[2023-09-30 11:31:47,272][00932] Avg episode reward: [(0, '1.655')]
[2023-09-30 11:31:48,805][00995] Updated weights for policy 0, policy_version 1062 (0.0012)
[2023-09-30 11:31:48,937][00995] Updated weights for policy 0, policy_version 1073 (0.0005)
[2023-09-30 11:31:50,859][00995] Updated weights for policy 0, policy_version 1083 (0.0009)
[2023-09-30 11:31:50,985][00995] Updated weights for policy 0, policy_version 1093 (0.0005)
[2023-09-30 11:31:52,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2184.5, 300 sec: 2252.8). Total num frames: 225280. Throughput: 0: 2204.5. Samples: 228014. Policy #0 lag: (min: 4.0, avg: 9.3, max: 24.0)
[2023-09-30 11:31:52,272][00932] Avg episode reward: [(0, '1.667')]
[2023-09-30 11:31:52,648][00995] Updated weights for policy 0, policy_version 1104 (0.0009)
[2023-09-30 11:31:52,775][00995] Updated weights for policy 0, policy_version 1114 (0.0011)
[2023-09-30 11:31:54,417][00995] Updated weights for policy 0, policy_version 1124 (0.0005)
[2023-09-30 11:31:54,559][00995] Updated weights for policy 0, policy_version 1135 (0.0005)
[2023-09-30 11:31:56,444][00995] Updated weights for policy 0, policy_version 1147 (0.0020)
[2023-09-30 11:31:56,569][00995] Updated weights for policy 0, policy_version 1158 (0.0009)
[2023-09-30 11:31:57,271][00932] Fps is (10 sec: 2457.6, 60 sec: 2184.5, 300 sec: 2262.6). Total num frames: 237568. Throughput: 0: 2203.3. Samples: 234710. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:31:57,277][00932] Avg episode reward: [(0, '1.663')]
[2023-09-30 11:31:57,287][00972] Saving logs/sf/Soccer_0/checkpoint_p0/checkpoint_000001160_237568.pth...
[2023-09-30 11:31:58,297][00995] Updated weights for policy 0, policy_version 1168 (0.0005)
[2023-09-30 11:31:58,417][00995] Updated weights for policy 0, policy_version 1178 (0.0012)
[2023-09-30 11:32:00,171][00995] Updated weights for policy 0, policy_version 1188 (0.0005)
[2023-09-30 11:32:00,309][00995] Updated weights for policy 0, policy_version 1198 (0.0005)
[2023-09-30 11:32:02,001][00995] Updated weights for policy 0, policy_version 1208 (0.0005)
[2023-09-30 11:32:02,117][00995] Updated weights for policy 0, policy_version 1218 (0.0009)
[2023-09-30 11:32:02,271][00932] Fps is (10 sec: 2457.6, 60 sec: 2252.8, 300 sec: 2271.4). Total num frames: 249856. Throughput: 0: 2197.7. Samples: 247774. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-09-30 11:32:02,272][00932] Avg episode reward: [(0, '1.663')]
[2023-09-30 11:32:03,893][00995] Updated weights for policy 0, policy_version 1228 (0.0006)
[2023-09-30 11:32:04,010][00995] Updated weights for policy 0, policy_version 1238 (0.0023)
[2023-09-30 11:32:05,798][00995] Updated weights for policy 0, policy_version 1248 (0.0005)
[2023-09-30 11:32:05,947][00995] Updated weights for policy 0, policy_version 1259 (0.0017)
[2023-09-30 11:32:07,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2184.5, 300 sec: 2243.9). Total num frames: 258048. Throughput: 0: 2176.3. Samples: 260558. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:32:07,272][00932] Avg episode reward: [(0, '1.646')]
[2023-09-30 11:32:07,879][00995] Updated weights for policy 0, policy_version 1269 (0.0005)
[2023-09-30 11:32:08,015][00995] Updated weights for policy 0, policy_version 1279 (0.0010)
[2023-09-30 11:32:09,719][00995] Updated weights for policy 0, policy_version 1289 (0.0011)
[2023-09-30 11:32:09,848][00995] Updated weights for policy 0, policy_version 1300 (0.0005)
[2023-09-30 11:32:11,749][00995] Updated weights for policy 0, policy_version 1310 (0.0007)
[2023-09-30 11:32:11,889][00995] Updated weights for policy 0, policy_version 1320 (0.0006)
[2023-09-30 11:32:12,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2184.5, 300 sec: 2252.8). Total num frames: 270336. Throughput: 0: 2178.4. Samples: 266936. Policy #0 lag: (min: 19.0, avg: 20.8, max: 39.0)
[2023-09-30 11:32:12,272][00932] Avg episode reward: [(0, '1.641')]
[2023-09-30 11:32:13,698][00995] Updated weights for policy 0, policy_version 1330 (0.0010)
[2023-09-30 11:32:13,818][00995] Updated weights for policy 0, policy_version 1340 (0.0015)
[2023-09-30 11:32:15,683][00995] Updated weights for policy 0, policy_version 1350 (0.0005)
[2023-09-30 11:32:15,824][00995] Updated weights for policy 0, policy_version 1360 (0.0005)
[2023-09-30 11:32:17,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2184.5, 300 sec: 2228.2). Total num frames: 278528. Throughput: 0: 2171.7. Samples: 279512. Policy #0 lag: (min: 16.0, avg: 25.4, max: 36.0)
[2023-09-30 11:32:17,272][00932] Avg episode reward: [(0, '1.639')]
[2023-09-30 11:32:17,596][00995] Updated weights for policy 0, policy_version 1370 (0.0005)
[2023-09-30 11:32:19,413][00995] Updated weights for policy 0, policy_version 1381 (0.0013)
[2023-09-30 11:32:19,550][00995] Updated weights for policy 0, policy_version 1391 (0.0010)
[2023-09-30 11:32:21,462][00995] Updated weights for policy 0, policy_version 1401 (0.0005)
[2023-09-30 11:32:21,610][00995] Updated weights for policy 0, policy_version 1412 (0.0005)
[2023-09-30 11:32:22,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2184.5, 300 sec: 2237.0). Total num frames: 290816. Throughput: 0: 2152.8. Samples: 291850. Policy #0 lag: (min: 19.0, avg: 20.2, max: 39.0)
[2023-09-30 11:32:22,272][00932] Avg episode reward: [(0, '1.639')]
[2023-09-30 11:32:23,453][00995] Updated weights for policy 0, policy_version 1422 (0.0019)
[2023-09-30 11:32:23,571][00995] Updated weights for policy 0, policy_version 1432 (0.0008)
[2023-09-30 11:32:25,477][00995] Updated weights for policy 0, policy_version 1442 (0.0010)
[2023-09-30 11:32:25,612][00995] Updated weights for policy 0, policy_version 1452 (0.0016)
[2023-09-30 11:32:27,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2116.3, 300 sec: 2214.9). Total num frames: 299008. Throughput: 0: 2145.1. Samples: 298114. Policy #0 lag: (min: 19.0, avg: 19.6, max: 39.0)
[2023-09-30 11:32:27,272][00932] Avg episode reward: [(0, '1.633')]
[2023-09-30 11:32:27,586][00995] Updated weights for policy 0, policy_version 1462 (0.0010)
[2023-09-30 11:32:27,717][00995] Updated weights for policy 0, policy_version 1472 (0.0005)
[2023-09-30 11:32:29,447][00995] Updated weights for policy 0, policy_version 1482 (0.0005)
[2023-09-30 11:32:29,568][00995] Updated weights for policy 0, policy_version 1492 (0.0013)
[2023-09-30 11:32:31,298][00995] Updated weights for policy 0, policy_version 1502 (0.0008)
[2023-09-30 11:32:31,432][00995] Updated weights for policy 0, policy_version 1513 (0.0005)
[2023-09-30 11:32:32,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2184.5, 300 sec: 2223.5). Total num frames: 311296. Throughput: 0: 2131.0. Samples: 310656. Policy #0 lag: (min: 16.0, avg: 25.7, max: 36.0)
[2023-09-30 11:32:32,280][00932] Avg episode reward: [(0, '1.631')]
[2023-09-30 11:32:33,162][00995] Updated weights for policy 0, policy_version 1524 (0.0009)
[2023-09-30 11:32:33,288][00995] Updated weights for policy 0, policy_version 1534 (0.0015)
[2023-09-30 11:32:35,070][00995] Updated weights for policy 0, policy_version 1544 (0.0006)
[2023-09-30 11:32:35,218][00995] Updated weights for policy 0, policy_version 1554 (0.0018)
[2023-09-30 11:32:36,914][00995] Updated weights for policy 0, policy_version 1564 (0.0009)
[2023-09-30 11:32:37,032][00995] Updated weights for policy 0, policy_version 1574 (0.0005)
[2023-09-30 11:32:37,271][00932] Fps is (10 sec: 2457.6, 60 sec: 2184.5, 300 sec: 2231.6). Total num frames: 323584. Throughput: 0: 2125.6. Samples: 323664. Policy #0 lag: (min: 19.0, avg: 20.2, max: 39.0)
[2023-09-30 11:32:37,280][00932] Avg episode reward: [(0, '1.631')]
[2023-09-30 11:32:38,889][00995] Updated weights for policy 0, policy_version 1584 (0.0013)
[2023-09-30 11:32:39,007][00995] Updated weights for policy 0, policy_version 1594 (0.0013)
[2023-09-30 11:32:40,771][00995] Updated weights for policy 0, policy_version 1605 (0.0005)
[2023-09-30 11:32:40,895][00995] Updated weights for policy 0, policy_version 1615 (0.0005)
[2023-09-30 11:32:42,272][00932] Fps is (10 sec: 2047.9, 60 sec: 2116.2, 300 sec: 2211.8). Total num frames: 331776. Throughput: 0: 2122.8. Samples: 330238. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:32:42,281][00932] Avg episode reward: [(0, '1.631')]
[2023-09-30 11:32:42,597][00995] Updated weights for policy 0, policy_version 1625 (0.0005)
[2023-09-30 11:32:42,733][00995] Updated weights for policy 0, policy_version 1636 (0.0012)
[2023-09-30 11:32:44,495][00995] Updated weights for policy 0, policy_version 1646 (0.0005)
[2023-09-30 11:32:44,644][00995] Updated weights for policy 0, policy_version 1656 (0.0006)
[2023-09-30 11:32:46,443][00995] Updated weights for policy 0, policy_version 1666 (0.0008)
[2023-09-30 11:32:46,577][00995] Updated weights for policy 0, policy_version 1676 (0.0005)
[2023-09-30 11:32:47,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2184.5, 300 sec: 2219.8). Total num frames: 344064. Throughput: 0: 2124.4. Samples: 343370. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-09-30 11:32:47,280][00932] Avg episode reward: [(0, '1.645')]
[2023-09-30 11:32:48,263][00995] Updated weights for policy 0, policy_version 1686 (0.0005)
[2023-09-30 11:32:48,396][00995] Updated weights for policy 0, policy_version 1696 (0.0005)
[2023-09-30 11:32:50,099][00995] Updated weights for policy 0, policy_version 1707 (0.0013)
[2023-09-30 11:32:50,251][00995] Updated weights for policy 0, policy_version 1717 (0.0005)
[2023-09-30 11:32:51,916][00995] Updated weights for policy 0, policy_version 1727 (0.0020)
[2023-09-30 11:32:52,035][00995] Updated weights for policy 0, policy_version 1737 (0.0006)
[2023-09-30 11:32:52,271][00932] Fps is (10 sec: 2457.8, 60 sec: 2184.5, 300 sec: 2227.2). Total num frames: 356352. Throughput: 0: 2138.5. Samples: 356792. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:32:52,272][00932] Avg episode reward: [(0, '1.648')]
[2023-09-30 11:32:53,724][00995] Updated weights for policy 0, policy_version 1747 (0.0011)
[2023-09-30 11:32:53,863][00995] Updated weights for policy 0, policy_version 1759 (0.0005)
[2023-09-30 11:32:55,824][00995] Updated weights for policy 0, policy_version 1769 (0.0011)
[2023-09-30 11:32:55,939][00995] Updated weights for policy 0, policy_version 1779 (0.0014)
[2023-09-30 11:32:57,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2116.3, 300 sec: 2209.4). Total num frames: 364544. Throughput: 0: 2139.4. Samples: 363208. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:32:57,280][00932] Avg episode reward: [(0, '1.648')]
[2023-09-30 11:32:57,669][00995] Updated weights for policy 0, policy_version 1790 (0.0013)
[2023-09-30 11:32:57,793][00995] Updated weights for policy 0, policy_version 1800 (0.0005)
[2023-09-30 11:32:59,489][00995] Updated weights for policy 0, policy_version 1810 (0.0009)
[2023-09-30 11:32:59,625][00995] Updated weights for policy 0, policy_version 1820 (0.0006)
[2023-09-30 11:33:01,364][00995] Updated weights for policy 0, policy_version 1830 (0.0008)
[2023-09-30 11:33:01,499][00995] Updated weights for policy 0, policy_version 1840 (0.0010)
[2023-09-30 11:33:02,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2116.3, 300 sec: 2216.7). Total num frames: 376832. Throughput: 0: 2148.6. Samples: 376198. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-09-30 11:33:02,272][00932] Avg episode reward: [(0, '1.639')]
[2023-09-30 11:33:03,330][00995] Updated weights for policy 0, policy_version 1851 (0.0005)
[2023-09-30 11:33:05,045][00995] Updated weights for policy 0, policy_version 1862 (0.0006)
[2023-09-30 11:33:05,157][00995] Updated weights for policy 0, policy_version 1872 (0.0005)
[2023-09-30 11:33:06,883][00995] Updated weights for policy 0, policy_version 1882 (0.0013)
[2023-09-30 11:33:07,015][00995] Updated weights for policy 0, policy_version 1892 (0.0017)
[2023-09-30 11:33:07,271][00932] Fps is (10 sec: 2457.6, 60 sec: 2184.5, 300 sec: 2223.5). Total num frames: 389120. Throughput: 0: 2170.6. Samples: 389528. Policy #0 lag: (min: 19.0, avg: 19.6, max: 39.0)
[2023-09-30 11:33:07,272][00932] Avg episode reward: [(0, '1.645')]
[2023-09-30 11:33:08,732][00995] Updated weights for policy 0, policy_version 1903 (0.0005)
[2023-09-30 11:33:08,870][00995] Updated weights for policy 0, policy_version 1914 (0.0010)
[2023-09-30 11:33:10,529][00995] Updated weights for policy 0, policy_version 1924 (0.0019)
[2023-09-30 11:33:10,656][00995] Updated weights for policy 0, policy_version 1934 (0.0011)
[2023-09-30 11:33:12,264][00995] Updated weights for policy 0, policy_version 1944 (0.0005)
[2023-09-30 11:33:12,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2116.3, 300 sec: 2207.3). Total num frames: 397312. Throughput: 0: 2179.7. Samples: 396202. Policy #0 lag: (min: 5.0, avg: 5.0, max: 5.0)
[2023-09-30 11:33:12,278][00932] Avg episode reward: [(0, '1.647')]
[2023-09-30 11:33:12,401][00995] Updated weights for policy 0, policy_version 1955 (0.0015)
[2023-09-30 11:33:14,349][00995] Updated weights for policy 0, policy_version 1965 (0.0007)
[2023-09-30 11:33:14,485][00995] Updated weights for policy 0, policy_version 1975 (0.0005)
[2023-09-30 11:33:16,130][00995] Updated weights for policy 0, policy_version 1985 (0.0005)
[2023-09-30 11:33:16,256][00995] Updated weights for policy 0, policy_version 1995 (0.0005)
[2023-09-30 11:33:17,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2184.5, 300 sec: 2214.1). Total num frames: 409600. Throughput: 0: 2197.1. Samples: 409524. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:33:17,280][00932] Avg episode reward: [(0, '1.645')]
[2023-09-30 11:33:17,948][00995] Updated weights for policy 0, policy_version 2005 (0.0008)
[2023-09-30 11:33:18,091][00995] Updated weights for policy 0, policy_version 2015 (0.0011)
[2023-09-30 11:33:19,889][00995] Updated weights for policy 0, policy_version 2025 (0.0008)
[2023-09-30 11:33:20,022][00995] Updated weights for policy 0, policy_version 2035 (0.0010)
[2023-09-30 11:33:21,635][00995] Updated weights for policy 0, policy_version 2045 (0.0005)
[2023-09-30 11:33:21,763][00995] Updated weights for policy 0, policy_version 2055 (0.0005)
[2023-09-30 11:33:22,271][00932] Fps is (10 sec: 2457.6, 60 sec: 2184.5, 300 sec: 2220.5). Total num frames: 421888. Throughput: 0: 2200.8. Samples: 422700. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-09-30 11:33:22,280][00932] Avg episode reward: [(0, '1.660')]
[2023-09-30 11:33:23,419][00995] Updated weights for policy 0, policy_version 2065 (0.0010)
[2023-09-30 11:33:23,546][00995] Updated weights for policy 0, policy_version 2075 (0.0008)
[2023-09-30 11:33:25,378][00995] Updated weights for policy 0, policy_version 2085 (0.0011)
[2023-09-30 11:33:25,510][00995] Updated weights for policy 0, policy_version 2095 (0.0011)
[2023-09-30 11:33:27,255][00995] Updated weights for policy 0, policy_version 2105 (0.0013)
[2023-09-30 11:33:27,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2184.5, 300 sec: 2205.5). Total num frames: 430080. Throughput: 0: 2204.2. Samples: 429426. Policy #0 lag: (min: 11.0, avg: 11.0, max: 11.0)
[2023-09-30 11:33:27,272][00932] Avg episode reward: [(0, '1.658')]
[2023-09-30 11:33:27,393][00995] Updated weights for policy 0, policy_version 2116 (0.0005)
[2023-09-30 11:33:29,160][00995] Updated weights for policy 0, policy_version 2126 (0.0011)
[2023-09-30 11:33:29,301][00995] Updated weights for policy 0, policy_version 2136 (0.0005)
[2023-09-30 11:33:31,135][00995] Updated weights for policy 0, policy_version 2146 (0.0006)
[2023-09-30 11:33:31,249][00995] Updated weights for policy 0, policy_version 2156 (0.0007)
[2023-09-30 11:33:32,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2184.5, 300 sec: 2211.8). Total num frames: 442368. Throughput: 0: 2195.2. Samples: 442154. Policy #0 lag: (min: 19.0, avg: 20.2, max: 39.0)
[2023-09-30 11:33:32,272][00932] Avg episode reward: [(0, '1.665')]
[2023-09-30 11:33:33,092][00995] Updated weights for policy 0, policy_version 2166 (0.0007)
[2023-09-30 11:33:33,217][00995] Updated weights for policy 0, policy_version 2176 (0.0005)
[2023-09-30 11:33:35,099][00995] Updated weights for policy 0, policy_version 2187 (0.0009)
[2023-09-30 11:33:35,230][00995] Updated weights for policy 0, policy_version 2197 (0.0010)
[2023-09-30 11:33:37,135][00995] Updated weights for policy 0, policy_version 2207 (0.0005)
[2023-09-30 11:33:37,268][00995] Updated weights for policy 0, policy_version 2219 (0.0008)
[2023-09-30 11:33:37,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2116.3, 300 sec: 2197.9). Total num frames: 450560. Throughput: 0: 2177.6. Samples: 454782. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:33:37,280][00932] Avg episode reward: [(0, '1.658')]
[2023-09-30 11:33:38,992][00995] Updated weights for policy 0, policy_version 2229 (0.0005)
[2023-09-30 11:33:39,104][00995] Updated weights for policy 0, policy_version 2239 (0.0005)
[2023-09-30 11:33:40,856][00995] Updated weights for policy 0, policy_version 2249 (0.0011)
[2023-09-30 11:33:40,995][00995] Updated weights for policy 0, policy_version 2259 (0.0005)
[2023-09-30 11:33:42,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2184.6, 300 sec: 2204.0). Total num frames: 462848. Throughput: 0: 2177.2. Samples: 461180. Policy #0 lag: (min: 10.0, avg: 17.2, max: 30.0)
[2023-09-30 11:33:42,280][00932] Avg episode reward: [(0, '1.652')]
[2023-09-30 11:33:42,780][00995] Updated weights for policy 0, policy_version 2269 (0.0006)
[2023-09-30 11:33:42,906][00995] Updated weights for policy 0, policy_version 2279 (0.0009)
[2023-09-30 11:33:44,673][00995] Updated weights for policy 0, policy_version 2289 (0.0006)
[2023-09-30 11:33:44,795][00995] Updated weights for policy 0, policy_version 2299 (0.0005)
[2023-09-30 11:33:46,662][00995] Updated weights for policy 0, policy_version 2309 (0.0005)
[2023-09-30 11:33:46,795][00995] Updated weights for policy 0, policy_version 2320 (0.0005)
[2023-09-30 11:33:47,271][00932] Fps is (10 sec: 2457.6, 60 sec: 2184.5, 300 sec: 2209.9). Total num frames: 475136. Throughput: 0: 2173.3. Samples: 473996. Policy #0 lag: (min: 19.0, avg: 20.7, max: 39.0)
[2023-09-30 11:33:47,272][00932] Avg episode reward: [(0, '1.655')]
[2023-09-30 11:33:48,527][00995] Updated weights for policy 0, policy_version 2330 (0.0010)
[2023-09-30 11:33:48,647][00995] Updated weights for policy 0, policy_version 2340 (0.0010)
[2023-09-30 11:33:50,361][00995] Updated weights for policy 0, policy_version 2350 (0.0005)
[2023-09-30 11:33:52,099][00995] Updated weights for policy 0, policy_version 2361 (0.0005)
[2023-09-30 11:33:52,220][00995] Updated weights for policy 0, policy_version 2371 (0.0008)
[2023-09-30 11:33:52,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2116.3, 300 sec: 2196.9). Total num frames: 483328. Throughput: 0: 2170.3. Samples: 487190. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-09-30 11:33:52,272][00932] Avg episode reward: [(0, '1.654')]
[2023-09-30 11:33:54,007][00995] Updated weights for policy 0, policy_version 2382 (0.0005)
[2023-09-30 11:33:54,147][00995] Updated weights for policy 0, policy_version 2392 (0.0006)
[2023-09-30 11:33:55,829][00995] Updated weights for policy 0, policy_version 2403 (0.0011)
[2023-09-30 11:33:55,973][00995] Updated weights for policy 0, policy_version 2414 (0.0005)
[2023-09-30 11:33:57,271][00932] Fps is (10 sec: 2048.0, 60 sec: 2184.5, 300 sec: 2202.7). Total num frames: 495616. Throughput: 0: 2168.0. Samples: 493764. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:33:57,272][00932] Avg episode reward: [(0, '1.649')]
[2023-09-30 11:33:57,282][00972] Saving logs/sf/Soccer_0/checkpoint_p0/checkpoint_000002420_495616.pth...
[2023-09-30 11:33:57,511][00995] Updated weights for policy 0, policy_version 2424 (0.0015)
[2023-09-30 11:33:57,620][00995] Updated weights for policy 0, policy_version 2434 (0.0012)
[2023-09-30 11:33:59,240][00995] Updated weights for policy 0, policy_version 2444 (0.0011)
[2023-09-30 11:33:59,371][00995] Updated weights for policy 0, policy_version 2454 (0.0005)
[2023-09-30 11:34:00,871][00995] Updated weights for policy 0, policy_version 2464 (0.0005)
[2023-09-30 11:34:00,992][00995] Updated weights for policy 0, policy_version 2474 (0.0014)
[2023-09-30 11:34:02,271][00932] Fps is (10 sec: 2457.6, 60 sec: 2184.5, 300 sec: 2208.3). Total num frames: 507904. Throughput: 0: 2195.8. Samples: 508334. Policy #0 lag: (min: 19.0, avg: 19.6, max: 39.0)
[2023-09-30 11:34:02,272][00932] Avg episode reward: [(0, '1.664')]
[2023-09-30 11:34:02,424][00995] Updated weights for policy 0, policy_version 2484 (0.0010)
[2023-09-30 11:34:02,539][00995] Updated weights for policy 0, policy_version 2494 (0.0005)
[2023-09-30 11:34:04,050][00995] Updated weights for policy 0, policy_version 2504 (0.0005)
[2023-09-30 11:34:04,179][00995] Updated weights for policy 0, policy_version 2514 (0.0008)
[2023-09-30 11:34:05,628][00995] Updated weights for policy 0, policy_version 2524 (0.0005)
[2023-09-30 11:34:05,749][00995] Updated weights for policy 0, policy_version 2535 (0.0005)
[2023-09-30 11:34:07,271][00932] Fps is (10 sec: 2457.6, 60 sec: 2184.5, 300 sec: 2213.6). Total num frames: 520192. Throughput: 0: 2246.8. Samples: 523806. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:34:07,273][00995] Updated weights for policy 0, policy_version 2546 (0.0005)
[2023-09-30 11:34:07,281][00932] Avg episode reward: [(0, '1.675')]
[2023-09-30 11:34:07,413][00995] Updated weights for policy 0, policy_version 2557 (0.0005)
[2023-09-30 11:34:08,759][00995] Updated weights for policy 0, policy_version 2568 (0.0010)
[2023-09-30 11:34:08,909][00995] Updated weights for policy 0, policy_version 2579 (0.0014)
[2023-09-30 11:34:10,260][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000005
[2023-09-30 11:34:11,816][00995] Updated weights for policy 0, policy_version 2589 (0.0010)
[2023-09-30 11:34:11,945][00995] Updated weights for policy 0, policy_version 2599 (0.0005)
[2023-09-30 11:34:12,273][00932] Fps is (10 sec: 2866.8, 60 sec: 2321.0, 300 sec: 2235.7). Total num frames: 536576. Throughput: 0: 2273.6. Samples: 531740. Policy #0 lag: (min: 19.0, avg: 19.2, max: 23.0)
[2023-09-30 11:34:12,274][00932] Avg episode reward: [(0, '1.690')]
[2023-09-30 11:34:13,368][00995] Updated weights for policy 0, policy_version 2610 (0.0010)
[2023-09-30 11:34:13,504][00995] Updated weights for policy 0, policy_version 2621 (0.0005)
[2023-09-30 11:34:14,800][00995] Updated weights for policy 0, policy_version 2631 (0.0010)
[2023-09-30 11:34:14,943][00995] Updated weights for policy 0, policy_version 2642 (0.0005)
[2023-09-30 11:34:16,432][00995] Updated weights for policy 0, policy_version 2653 (0.0005)
[2023-09-30 11:34:16,566][00995] Updated weights for policy 0, policy_version 2663 (0.0013)
[2023-09-30 11:34:17,271][00932] Fps is (10 sec: 2867.2, 60 sec: 2321.1, 300 sec: 2240.3). Total num frames: 548864. Throughput: 0: 2353.4. Samples: 548058. Policy #0 lag: (min: 18.0, avg: 25.2, max: 38.0)
[2023-09-30 11:34:17,272][00932] Avg episode reward: [(0, '1.683')]
[2023-09-30 11:34:17,817][00995] Updated weights for policy 0, policy_version 2674 (0.0005)
[2023-09-30 11:34:19,282][00995] Updated weights for policy 0, policy_version 2688 (0.0005)
[2023-09-30 11:34:19,344][00972] Early stopping after 4 epochs (8 sgd steps), loss delta 0.0000002
[2023-09-30 11:34:20,720][00995] Updated weights for policy 0, policy_version 2699 (0.0009)
[2023-09-30 11:34:20,857][00995] Updated weights for policy 0, policy_version 2709 (0.0005)
[2023-09-30 11:34:20,893][00972] Early stopping after 10 epochs (20 sgd steps), loss delta 0.0000009
[2023-09-30 11:34:22,219][00995] Updated weights for policy 0, policy_version 2719 (0.0005)
[2023-09-30 11:34:22,271][00932] Fps is (10 sec: 2457.9, 60 sec: 2321.1, 300 sec: 2244.6). Total num frames: 561152. Throughput: 0: 2443.5. Samples: 564738. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2023-09-30 11:34:22,272][00932] Avg episode reward: [(0, '1.695')]
[2023-09-30 11:34:22,363][00995] Updated weights for policy 0, policy_version 2730 (0.0016)
[2023-09-30 11:34:23,647][00995] Updated weights for policy 0, policy_version 2740 (0.0005)
[2023-09-30 11:34:23,770][00995] Updated weights for policy 0, policy_version 2750 (0.0011)
[2023-09-30 11:34:25,192][00995] Updated weights for policy 0, policy_version 2760 (0.0010)
[2023-09-30 11:34:25,325][00995] Updated weights for policy 0, policy_version 2770 (0.0005)
[2023-09-30 11:34:26,657][00995] Updated weights for policy 0, policy_version 2780 (0.0009)
[2023-09-30 11:34:26,787][00995] Updated weights for policy 0, policy_version 2791 (0.0008)
[2023-09-30 11:34:27,271][00932] Fps is (10 sec: 2867.2, 60 sec: 2457.6, 300 sec: 2264.8). Total num frames: 577536. Throughput: 0: 2485.5. Samples: 573028. Policy #0 lag: (min: 19.0, avg: 23.1, max: 39.0)
[2023-09-30 11:34:27,272][00932] Avg episode reward: [(0, '1.759')]
[2023-09-30 11:34:27,275][00972] Saving new best policy, reward=1.759!
[2023-09-30 11:34:28,135][00995] Updated weights for policy 0, policy_version 2801 (0.0007)
[2023-09-30 11:34:28,264][00995] Updated weights for policy 0, policy_version 2811 (0.0017)
[2023-09-30 11:34:29,644][00995] Updated weights for policy 0, policy_version 2822 (0.0005)
[2023-09-30 11:34:29,712][00972] Early stopping after 8 epochs (16 sgd steps), loss delta 0.0000001
[2023-09-30 11:34:30,948][00995] Updated weights for policy 0, policy_version 2832 (0.0005)
[2023-09-30 11:34:31,084][00995] Updated weights for policy 0, policy_version 2843 (0.0006)
[2023-09-30 11:34:32,271][00932] Fps is (10 sec: 2867.2, 60 sec: 2457.6, 300 sec: 2268.6). Total num frames: 589824. Throughput: 0: 2578.3. Samples: 590018. Policy #0 lag: (min: 5.0, avg: 5.5, max: 21.0)
[2023-09-30 11:34:32,272][00932] Avg episode reward: [(0, '1.754')]
[2023-09-30 11:34:32,371][00995] Updated weights for policy 0, policy_version 2853 (0.0009)
[2023-09-30 11:34:32,525][00995] Updated weights for policy 0, policy_version 2864 (0.0007)
[2023-09-30 11:34:33,805][00995] Updated weights for policy 0, policy_version 2874 (0.0005)
[2023-09-30 11:34:33,938][00995] Updated weights for policy 0, policy_version 2884 (0.0005)
[2023-09-30 11:34:35,270][00995] Updated weights for policy 0, policy_version 2895 (0.0007)
[2023-09-30 11:34:35,399][00995] Updated weights for policy 0, policy_version 2905 (0.0008)
[2023-09-30 11:34:36,639][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:34:37,271][00932] Fps is (10 sec: 2867.2, 60 sec: 2594.1, 300 sec: 2287.6). Total num frames: 606208. Throughput: 0: 2666.0. Samples: 607162. Policy #0 lag: (min: 19.0, avg: 19.0, max: 19.0)
[2023-09-30 11:34:37,272][00932] Avg episode reward: [(0, '1.758')]
[2023-09-30 11:34:38,025][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:34:38,035][00995] Updated weights for policy 0, policy_version 2916 (0.0005)
[2023-09-30 11:34:39,357][00972] Early stopping after 4 epochs (8 sgd steps), loss delta 0.0000004
[2023-09-30 11:34:40,615][00995] Updated weights for policy 0, policy_version 2926 (0.0012)
[2023-09-30 11:34:40,645][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000001
[2023-09-30 11:34:42,121][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:34:42,271][00932] Fps is (10 sec: 3276.8, 60 sec: 2662.4, 300 sec: 2305.9). Total num frames: 622592. Throughput: 0: 2721.4. Samples: 616226. Policy #0 lag: (min: 6.0, avg: 7.4, max: 10.0)
[2023-09-30 11:34:42,271][00932] Avg episode reward: [(0, '1.692')]
[2023-09-30 11:34:43,499][00995] Updated weights for policy 0, policy_version 2936 (0.0012)
[2023-09-30 11:34:43,579][00972] Early stopping after 5 epochs (10 sgd steps), loss delta 0.0000002
[2023-09-30 11:34:44,849][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:34:44,851][00995] Updated weights for policy 0, policy_version 2946 (0.0005)
[2023-09-30 11:34:46,135][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:34:47,272][00932] Fps is (10 sec: 2867.1, 60 sec: 2662.4, 300 sec: 2308.6). Total num frames: 634880. Throughput: 0: 2798.3. Samples: 634260. Policy #0 lag: (min: 6.0, avg: 7.4, max: 10.0)
[2023-09-30 11:34:47,273][00932] Avg episode reward: [(0, '1.698')]
[2023-09-30 11:34:47,538][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000004
[2023-09-30 11:34:48,971][00995] Updated weights for policy 0, policy_version 2957 (0.0011)
[2023-09-30 11:34:48,987][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:34:50,296][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:34:51,573][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:34:52,271][00932] Fps is (10 sec: 2867.2, 60 sec: 2798.9, 300 sec: 2325.9). Total num frames: 651264. Throughput: 0: 2856.4. Samples: 652344. Policy #0 lag: (min: 6.0, avg: 7.4, max: 10.0)
[2023-09-30 11:34:52,272][00932] Avg episode reward: [(0, '1.763')]
[2023-09-30 11:34:52,280][00972] Saving new best policy, reward=1.763!
[2023-09-30 11:34:52,932][00995] Updated weights for policy 0, policy_version 2967 (0.0012)
[2023-09-30 11:34:52,991][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:34:54,321][00995] Updated weights for policy 0, policy_version 2977 (0.0005)
[2023-09-30 11:34:54,331][00972] Early stopping after 4 epochs (8 sgd steps), loss delta 0.0000002
[2023-09-30 11:34:55,745][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000001
[2023-09-30 11:34:57,087][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:34:57,271][00932] Fps is (10 sec: 3277.0, 60 sec: 2867.2, 300 sec: 2342.6). Total num frames: 667648. Throughput: 0: 2880.4. Samples: 661352. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-09-30 11:34:57,272][00932] Avg episode reward: [(0, '1.829')]
[2023-09-30 11:34:57,285][00972] Saving new best policy, reward=1.829!
[2023-09-30 11:34:58,375][00995] Updated weights for policy 0, policy_version 2988 (0.0014)
[2023-09-30 11:34:58,404][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:34:59,817][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:01,150][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000002
[2023-09-30 11:35:01,151][00995] Updated weights for policy 0, policy_version 2998 (0.0009)
[2023-09-30 11:35:02,271][00932] Fps is (10 sec: 2867.2, 60 sec: 2867.2, 300 sec: 2344.6). Total num frames: 679936. Throughput: 0: 2919.0. Samples: 679412. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-09-30 11:35:02,280][00932] Avg episode reward: [(0, '1.828')]
[2023-09-30 11:35:02,460][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000008
[2023-09-30 11:35:03,894][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:05,217][00995] Updated weights for policy 0, policy_version 3009 (0.0005)
[2023-09-30 11:35:05,224][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:06,533][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:07,272][00932] Fps is (10 sec: 2867.1, 60 sec: 2935.4, 300 sec: 2360.4). Total num frames: 696320. Throughput: 0: 2949.8. Samples: 697478. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-09-30 11:35:07,272][00932] Avg episode reward: [(0, '1.760')]
[2023-09-30 11:35:07,903][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:09,322][00995] Updated weights for policy 0, policy_version 3019 (0.0005)
[2023-09-30 11:35:09,370][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:10,679][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000001
[2023-09-30 11:35:11,978][00995] Updated weights for policy 0, policy_version 3029 (0.0011)
[2023-09-30 11:35:11,988][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000001
[2023-09-30 11:35:12,271][00932] Fps is (10 sec: 3276.8, 60 sec: 2935.5, 300 sec: 2402.1). Total num frames: 712704. Throughput: 0: 2967.0. Samples: 706544. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-09-30 11:35:12,272][00932] Avg episode reward: [(0, '1.760')]
[2023-09-30 11:35:13,424][00972] Early stopping after 3 epochs (6 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:14,749][00995] Updated weights for policy 0, policy_version 3039 (0.0009)
[2023-09-30 11:35:14,757][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:16,098][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:17,271][00932] Fps is (10 sec: 2867.3, 60 sec: 2935.5, 300 sec: 2388.2). Total num frames: 724992. Throughput: 0: 2992.3. Samples: 724670. Policy #0 lag: (min: 1.0, avg: 1.0, max: 1.0)
[2023-09-30 11:35:17,273][00932] Avg episode reward: [(0, '1.693')]
[2023-09-30 11:35:17,430][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:18,761][00995] Updated weights for policy 0, policy_version 3049 (0.0005)
[2023-09-30 11:35:18,791][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:20,159][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:21,541][00995] Updated weights for policy 0, policy_version 3059 (0.0010)
[2023-09-30 11:35:21,548][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:22,271][00932] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 2402.1). Total num frames: 741376. Throughput: 0: 3012.8. Samples: 742740. Policy #0 lag: (min: 0.0, avg: 1.4, max: 4.0)
[2023-09-30 11:35:22,272][00932] Avg episode reward: [(0, '1.760')]
[2023-09-30 11:35:22,930][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:24,212][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:25,530][00995] Updated weights for policy 0, policy_version 3069 (0.0011)
[2023-09-30 11:35:25,569][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:26,926][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:27,271][00932] Fps is (10 sec: 3276.8, 60 sec: 3003.7, 300 sec: 2415.9). Total num frames: 757760. Throughput: 0: 3012.4. Samples: 751786. Policy #0 lag: (min: 1.0, avg: 1.2, max: 5.0)
[2023-09-30 11:35:27,272][00932] Avg episode reward: [(0, '1.760')]
[2023-09-30 11:35:28,411][00995] Updated weights for policy 0, policy_version 3079 (0.0010)
[2023-09-30 11:35:28,434][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:29,715][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:31,042][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:32,271][00932] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 2415.9). Total num frames: 770048. Throughput: 0: 3012.7. Samples: 769830. Policy #0 lag: (min: 1.0, avg: 1.2, max: 5.0)
[2023-09-30 11:35:32,272][00932] Avg episode reward: [(0, '1.760')]
[2023-09-30 11:35:32,315][00995] Updated weights for policy 0, policy_version 3089 (0.0005)
[2023-09-30 11:35:32,349][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:33,823][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:35,181][00995] Updated weights for policy 0, policy_version 3099 (0.0013)
[2023-09-30 11:35:35,194][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:36,512][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:37,271][00932] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 2429.8). Total num frames: 786432. Throughput: 0: 3012.2. Samples: 787892. Policy #0 lag: (min: 1.0, avg: 1.2, max: 5.0)
[2023-09-30 11:35:37,272][00932] Avg episode reward: [(0, '1.760')]
[2023-09-30 11:35:37,804][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:39,099][00995] Updated weights for policy 0, policy_version 3109 (0.0005)
[2023-09-30 11:35:39,137][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:40,613][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:41,910][00995] Updated weights for policy 0, policy_version 3119 (0.0005)
[2023-09-30 11:35:41,919][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000001
[2023-09-30 11:35:42,271][00932] Fps is (10 sec: 3276.8, 60 sec: 3003.7, 300 sec: 2443.7). Total num frames: 802816. Throughput: 0: 3013.6. Samples: 796962. Policy #0 lag: (min: 2.0, avg: 2.9, max: 6.0)
[2023-09-30 11:35:42,272][00932] Avg episode reward: [(0, '1.760')]
[2023-09-30 11:35:43,248][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000001
[2023-09-30 11:35:44,626][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:45,926][00995] Updated weights for policy 0, policy_version 3129 (0.0010)
[2023-09-30 11:35:45,959][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:47,271][00932] Fps is (10 sec: 2867.2, 60 sec: 3003.8, 300 sec: 2443.7). Total num frames: 815104. Throughput: 0: 3014.6. Samples: 815068. Policy #0 lag: (min: 2.0, avg: 2.9, max: 6.0)
[2023-09-30 11:35:47,276][00932] Avg episode reward: [(0, '1.828')]
[2023-09-30 11:35:47,440][00995] Updated weights for policy 0, policy_version 3139 (0.0006)
[2023-09-30 11:35:47,447][00972] Early stopping after 4 epochs (8 sgd steps), loss delta 0.0000002
[2023-09-30 11:35:48,776][00972] Early stopping after 4 epochs (8 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:50,107][00995] Updated weights for policy 0, policy_version 3149 (0.0005)
[2023-09-30 11:35:50,144][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:51,465][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:52,271][00932] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 2457.6). Total num frames: 831488. Throughput: 0: 3013.1. Samples: 833068. Policy #0 lag: (min: 2.0, avg: 2.9, max: 6.0)
[2023-09-30 11:35:52,272][00932] Avg episode reward: [(0, '1.760')]
[2023-09-30 11:35:52,792][00995] Updated weights for policy 0, policy_version 3160 (0.0007)
[2023-09-30 11:35:52,784][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000001
[2023-09-30 11:35:54,185][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:55,541][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000001
[2023-09-30 11:35:56,874][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:35:56,876][00995] Updated weights for policy 0, policy_version 3172 (0.0009)
[2023-09-30 11:35:57,271][00932] Fps is (10 sec: 3276.8, 60 sec: 3003.7, 300 sec: 2485.4). Total num frames: 847872. Throughput: 0: 3012.8. Samples: 842118. Policy #0 lag: (min: 3.0, avg: 3.0, max: 3.0)
[2023-09-30 11:35:57,272][00932] Avg episode reward: [(0, '1.760')]
[2023-09-30 11:35:57,278][00972] Saving logs/sf/Soccer_0/checkpoint_p0/checkpoint_000003172_847872.pth...
[2023-09-30 11:35:57,317][00972] Removing logs/sf/Soccer_0/checkpoint_p0/checkpoint_000001160_237568.pth
[2023-09-30 11:35:58,252][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000001
[2023-09-30 11:35:59,640][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000002
[2023-09-30 11:36:00,963][00995] Updated weights for policy 0, policy_version 3182 (0.0005)
[2023-09-30 11:36:00,976][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:02,271][00932] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 2485.4). Total num frames: 860160. Throughput: 0: 3011.1. Samples: 860168. Policy #0 lag: (min: 2.0, avg: 3.2, max: 6.0)
[2023-09-30 11:36:02,272][00932] Avg episode reward: [(0, '1.760')]
[2023-09-30 11:36:02,307][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:03,691][00995] Updated weights for policy 0, policy_version 3192 (0.0005)
[2023-09-30 11:36:03,791][00972] Early stopping after 6 epochs (12 sgd steps), loss delta 0.0000001
[2023-09-30 11:36:05,087][00995] Updated weights for policy 0, policy_version 3202 (0.0010)
[2023-09-30 11:36:05,242][00995] Updated weights for policy 0, policy_version 3212 (0.0009)
[2023-09-30 11:36:06,500][00995] Updated weights for policy 0, policy_version 3222 (0.0014)
[2023-09-30 11:36:06,659][00995] Updated weights for policy 0, policy_version 3234 (0.0005)
[2023-09-30 11:36:07,271][00932] Fps is (10 sec: 2867.2, 60 sec: 3003.8, 300 sec: 2499.3). Total num frames: 876544. Throughput: 0: 2998.0. Samples: 877652. Policy #0 lag: (min: 17.0, avg: 18.8, max: 29.0)
[2023-09-30 11:36:07,280][00932] Avg episode reward: [(0, '1.760')]
[2023-09-30 11:36:07,987][00995] Updated weights for policy 0, policy_version 3245 (0.0008)
[2023-09-30 11:36:08,028][00972] Early stopping after 4 epochs (8 sgd steps), loss delta 0.0000003
[2023-09-30 11:36:09,409][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:10,705][00995] Updated weights for policy 0, policy_version 3255 (0.0011)
[2023-09-30 11:36:10,712][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:12,062][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000003
[2023-09-30 11:36:12,271][00932] Fps is (10 sec: 3276.8, 60 sec: 3003.7, 300 sec: 2527.0). Total num frames: 892928. Throughput: 0: 2994.8. Samples: 886552. Policy #0 lag: (min: 17.0, avg: 18.8, max: 29.0)
[2023-09-30 11:36:12,280][00932] Avg episode reward: [(0, '1.760')]
[2023-09-30 11:36:13,483][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:14,779][00995] Updated weights for policy 0, policy_version 3266 (0.0005)
[2023-09-30 11:36:14,808][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:16,255][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:17,271][00932] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 2527.0). Total num frames: 905216. Throughput: 0: 2993.6. Samples: 904542. Policy #0 lag: (min: 17.0, avg: 18.8, max: 29.0)
[2023-09-30 11:36:17,280][00932] Avg episode reward: [(0, '1.759')]
[2023-09-30 11:36:17,583][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:17,585][00995] Updated weights for policy 0, policy_version 3276 (0.0008)
[2023-09-30 11:36:18,911][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:20,238][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:21,696][00995] Updated weights for policy 0, policy_version 3286 (0.0007)
[2023-09-30 11:36:21,714][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:22,271][00932] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 2540.9). Total num frames: 921600. Throughput: 0: 2993.6. Samples: 922602. Policy #0 lag: (min: 17.0, avg: 18.8, max: 29.0)
[2023-09-30 11:36:22,280][00932] Avg episode reward: [(0, '1.691')]
[2023-09-30 11:36:22,995][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:24,296][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:24,299][00995] Updated weights for policy 0, policy_version 3296 (0.0018)
[2023-09-30 11:36:25,683][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:27,070][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:27,271][00932] Fps is (10 sec: 3276.8, 60 sec: 3003.7, 300 sec: 2568.7). Total num frames: 937984. Throughput: 0: 2994.7. Samples: 931724. Policy #0 lag: (min: 17.0, avg: 18.8, max: 29.0)
[2023-09-30 11:36:27,280][00932] Avg episode reward: [(0, '1.759')]
[2023-09-30 11:36:28,393][00995] Updated weights for policy 0, policy_version 3306 (0.0014)
[2023-09-30 11:36:28,410][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:29,871][00972] Early stopping after 5 epochs (10 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:29,872][00995] Updated weights for policy 0, policy_version 3318 (0.0006)
[2023-09-30 11:36:31,153][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000009
[2023-09-30 11:36:32,271][00932] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 2568.7). Total num frames: 950272. Throughput: 0: 2992.9. Samples: 949750. Policy #0 lag: (min: 17.0, avg: 18.8, max: 29.0)
[2023-09-30 11:36:32,272][00932] Avg episode reward: [(0, '1.760')]
[2023-09-30 11:36:32,533][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:33,836][00995] Updated weights for policy 0, policy_version 3328 (0.0015)
[2023-09-30 11:36:33,858][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000001
[2023-09-30 11:36:35,269][00972] Early stopping after 4 epochs (8 sgd steps), loss delta 0.0000008
[2023-09-30 11:36:35,270][00995] Updated weights for policy 0, policy_version 3338 (0.0007)
[2023-09-30 11:36:36,666][00972] Early stopping after 3 epochs (6 sgd steps), loss delta 0.0000002
[2023-09-30 11:36:37,271][00932] Fps is (10 sec: 2867.2, 60 sec: 3003.7, 300 sec: 2582.6). Total num frames: 966656. Throughput: 0: 2992.1. Samples: 967714. Policy #0 lag: (min: 17.0, avg: 18.8, max: 29.0)
[2023-09-30 11:36:37,272][00932] Avg episode reward: [(0, '1.761')]
[2023-09-30 11:36:37,975][00995] Updated weights for policy 0, policy_version 3348 (0.0005)
[2023-09-30 11:36:37,996][00972] Early stopping after 3 epochs (6 sgd steps), loss delta 0.0000002
[2023-09-30 11:36:39,345][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000001
[2023-09-30 11:36:40,661][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000009
[2023-09-30 11:36:40,664][00995] Updated weights for policy 0, policy_version 3358 (0.0005)
[2023-09-30 11:36:42,176][00972] Early stopping after 6 epochs (12 sgd steps), loss delta 0.0000004
[2023-09-30 11:36:42,179][00995] Updated weights for policy 0, policy_version 3370 (0.0006)
[2023-09-30 11:36:42,271][00932] Fps is (10 sec: 3276.8, 60 sec: 3003.7, 300 sec: 2610.3). Total num frames: 983040. Throughput: 0: 2992.5. Samples: 976780. Policy #0 lag: (min: 0.0, avg: 1.2, max: 4.0)
[2023-09-30 11:36:42,280][00932] Avg episode reward: [(0, '1.761')]
[2023-09-30 11:36:43,391][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000001
[2023-09-30 11:36:44,794][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000001
[2023-09-30 11:36:46,177][00995] Updated weights for policy 0, policy_version 3380 (0.0008)
[2023-09-30 11:36:46,217][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:47,272][00932] Fps is (10 sec: 2867.1, 60 sec: 3003.7, 300 sec: 2610.3). Total num frames: 995328. Throughput: 0: 2992.4. Samples: 994826. Policy #0 lag: (min: 0.0, avg: 1.2, max: 4.0)
[2023-09-30 11:36:47,281][00932] Avg episode reward: [(0, '1.693')]
[2023-09-30 11:36:47,553][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:48,848][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:48,852][00995] Updated weights for policy 0, policy_version 3390 (0.0005)
[2023-09-30 11:36:50,192][00972] Early stopping after 2 epochs (4 sgd steps), loss delta 0.0000000
[2023-09-30 11:36:50,196][00972] Saving logs/sf/Soccer_0/checkpoint_p0/checkpoint_000003394_1007616.pth...
[2023-09-30 11:36:50,196][00932] Component Batcher_0 stopped!
[2023-09-30 11:36:50,196][00972] Stopping Batcher_0...
[2023-09-30 11:36:50,206][00972] Loop batcher_evt_loop terminating...
[2023-09-30 11:36:50,224][00995] Weights refcount: 2 0
[2023-09-30 11:36:50,225][00995] Stopping InferenceWorker_p0-w0...
[2023-09-30 11:36:50,225][00995] Loop inference_proc0-0_evt_loop terminating...
[2023-09-30 11:36:50,225][00932] Component InferenceWorker_p0-w0 stopped!
[2023-09-30 11:36:50,231][00972] Removing logs/sf/Soccer_0/checkpoint_p0/checkpoint_000002420_495616.pth
[2023-09-30 11:36:50,234][00972] Saving logs/sf/Soccer_0/checkpoint_p0/checkpoint_000003394_1007616.pth...
[2023-09-30 11:36:50,263][00972] Stopping LearnerWorker_p0...
[2023-09-30 11:36:50,264][00972] Loop learner_proc0_evt_loop terminating...
[2023-09-30 11:36:50,263][00932] Component LearnerWorker_p0 stopped!
[2023-09-30 11:36:52,207][00998] Stopping RolloutWorker_w1...
[2023-09-30 11:36:52,207][00989] Stopping RolloutWorker_w8...
[2023-09-30 11:36:52,207][00932] Component RolloutWorker_w1 stopped!
[2023-09-30 11:36:52,207][00998] Loop rollout_proc1_evt_loop terminating...
[2023-09-30 11:36:52,207][00989] Loop rollout_proc8_evt_loop terminating...
[2023-09-30 11:36:52,207][00932] Component RolloutWorker_w8 stopped!
[2023-09-30 11:36:52,208][00932] Component RolloutWorker_w4 stopped!
[2023-09-30 11:36:52,208][00932] Component RolloutWorker_w5 stopped!
[2023-09-30 11:36:52,208][00996] Stopping RolloutWorker_w9...
[2023-09-30 11:36:52,209][00994] Stopping RolloutWorker_w6...
[2023-09-30 11:36:52,209][00994] Loop rollout_proc6_evt_loop terminating...
[2023-09-30 11:36:52,209][00990] Stopping RolloutWorker_w2...
[2023-09-30 11:36:52,209][00996] Loop rollout_proc9_evt_loop terminating...
[2023-09-30 11:36:52,210][00990] Loop rollout_proc2_evt_loop terminating...
[2023-09-30 11:36:52,214][00997] Stopping RolloutWorker_w0...
[2023-09-30 11:36:52,214][00997] Loop rollout_proc0_evt_loop terminating...
[2023-09-30 11:36:52,214][00988] Stopping RolloutWorker_w3...
[2023-09-30 11:36:52,215][00988] Loop rollout_proc3_evt_loop terminating...
[2023-09-30 11:36:52,207][01000] Stopping RolloutWorker_w4...
[2023-09-30 11:36:52,218][01000] Loop rollout_proc4_evt_loop terminating...
[2023-09-30 11:36:52,209][00932] Component RolloutWorker_w9 stopped!
[2023-09-30 11:36:52,207][00987] Stopping RolloutWorker_w5...
[2023-09-30 11:36:52,215][00999] Stopping RolloutWorker_w7...
[2023-09-30 11:36:52,222][00932] Component RolloutWorker_w6 stopped!
[2023-09-30 11:36:52,222][00987] Loop rollout_proc5_evt_loop terminating...
[2023-09-30 11:36:52,222][00932] Component RolloutWorker_w2 stopped!
[2023-09-30 11:36:52,222][00932] Component RolloutWorker_w0 stopped!
[2023-09-30 11:36:52,222][00932] Component RolloutWorker_w3 stopped!
[2023-09-30 11:36:52,222][00932] Component RolloutWorker_w7 stopped!
[2023-09-30 11:36:52,222][00932] Waiting for process learner_proc0 to stop...
[2023-09-30 11:36:52,222][00999] Loop rollout_proc7_evt_loop terminating...
[2023-09-30 11:36:52,222][00932] Waiting for process inference_proc0-0 to join...
[2023-09-30 11:36:52,223][00932] Waiting for process rollout_proc0 to join...
[2023-09-30 11:36:53,436][00932] Waiting for process rollout_proc1 to join...
[2023-09-30 11:36:53,436][00932] Waiting for process rollout_proc2 to join...
[2023-09-30 11:36:53,437][00932] Waiting for process rollout_proc3 to join...
[2023-09-30 11:36:53,437][00932] Waiting for process rollout_proc4 to join...
[2023-09-30 11:36:53,440][00932] Waiting for process rollout_proc5 to join...
[2023-09-30 11:36:53,440][00932] Waiting for process rollout_proc6 to join...
[2023-09-30 11:36:53,440][00932] Waiting for process rollout_proc7 to join...
[2023-09-30 11:36:53,440][00932] Waiting for process rollout_proc8 to join...
[2023-09-30 11:36:53,440][00932] Waiting for process rollout_proc9 to join...
[2023-09-30 11:36:53,441][00932] Batcher 0 profile tree view:
batching: 2.6776, releasing_batches: 0.0038
[2023-09-30 11:36:53,441][00932] InferenceWorker_p0-w0 profile tree view:
wait_policy: 0.0000
  wait_policy_total: 86.1710
update_model: 6.6773
  weight_update: 0.0018
one_step: 0.0026
  handle_policy_step: 291.3639
    deserialize: 4.5624, stack: 1.3360, obs_to_device_normalize: 46.1786, forward: 190.4283, send_messages: 14.7492
    prepare_outputs: 23.0132
      to_cpu: 10.8737
[2023-09-30 11:36:53,441][00932] Learner 0 profile tree view:
misc: 0.0012, prepare_batch: 3.0524
train: 44.2716
  epoch_init: 0.0149, minibatch_init: 0.2912, losses_postprocess: 1.0914, kl_divergence: 2.7680, after_optimizer: 1.4903
  calculate_losses: 16.7527
    losses_init: 0.0077, forward_head: 0.9305, bptt_initial: 5.0640, tail: 3.3763, advantages_returns: 0.4603, losses: 3.2970
    bptt: 3.0248
      bptt_forward_core: 2.8835
  update: 21.1351
    clip: 5.4551
[2023-09-30 11:36:53,441][00932] RolloutWorker_w0 profile tree view:
wait_for_trajectories: 0.0730, enqueue_policy_requests: 3.4506, env_step: 282.2686, overhead: 3.0704, complete_rollouts: 0.3769
save_policy_outputs: 5.4261
  split_output_tensors: 1.9091
[2023-09-30 11:36:53,441][00932] RolloutWorker_w9 profile tree view:
wait_for_trajectories: 0.0672, enqueue_policy_requests: 3.2101, env_step: 305.5341, overhead: 2.8182, complete_rollouts: 0.2212
save_policy_outputs: 4.7567
  split_output_tensors: 1.6282
[2023-09-30 11:36:53,441][00932] Loop Runner_EvtLoop terminating...
[2023-09-30 11:36:53,442][00932] Runner profile tree view:
main_loop: 411.0785
[2023-09-30 11:36:53,442][00932] Collected {0: 1007616}, FPS: 2451.2
